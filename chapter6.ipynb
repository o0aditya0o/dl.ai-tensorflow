{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
                "from tensorflow.keras import layers\n",
                "\n",
                "# Set the local weights file\n",
                "local_weights_file = './inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
                "\n",
                "# Initialize the pre-trained model\n",
                "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
                "                                include_top=False,\n",
                "                                weights=None)\n",
                "\n",
                "# Load the local weights\n",
                "pre_trained_model.load_weights(local_weights_file)\n",
                "\n",
                "# Freeze the layers\n",
                "for layer in pre_trained_model.layers:\n",
                "    layer.trainable = False\n",
                "\n",
                "pre_trained_model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "last_layer = pre_trained_model.get_layer('mixed7')\n",
                "last_output = last_layer.output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = tf.keras.layers.Flatten()(last_output)\n",
                "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
                "x = tf.keras.layers.Dropout(0.2)(x)\n",
                "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
                "model = tf.keras.Model(pre_trained_model.input, x)\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Contents of base directory: ['.DS_Store', 'train', 'validation']\n",
                        "\n",
                        "Contents of train directory: ['dogs', 'cats', '.DS_Store']\n",
                        "\n",
                        "Contents of validation directory: ['dogs', 'cats', '.DS_Store']\n"
                    ]
                }
            ],
            "source": [
                "BASE_DIR = '/Users/aditya/Desktop/Kaggle/catdog/prepared_data'\n",
                "\n",
                "train_dir = os.path.join(BASE_DIR, 'train')\n",
                "validation_dir = os.path.join(BASE_DIR, 'validation')\n",
                "\n",
                "# Directory with training cat/dog pictures\n",
                "train_cats_dir = os.path.join(train_dir, 'cats')\n",
                "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
                "\n",
                "# Directory with validation cat/dog pictures\n",
                "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
                "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
                "\n",
                "print(f\"Contents of base directory: {os.listdir(BASE_DIR)}\")\n",
                "\n",
                "print(f\"\\nContents of train directory: {os.listdir(train_dir)}\")\n",
                "\n",
                "print(f\"\\nContents of validation directory: {os.listdir(validation_dir)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 22546 files belonging to 2 classes.\n",
                        "Found 2454 files belonging to 2 classes.\n"
                    ]
                }
            ],
            "source": [
                "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
                "    train_dir,\n",
                "    image_size = (150, 150),\n",
                "    batch_size = 20,\n",
                "    label_mode = 'binary'\n",
                ")\n",
                "\n",
                "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
                "    validation_dir,\n",
                "    image_size = (150, 150),\n",
                "    batch_size = 20,\n",
                "    label_mode = 'binary'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess(image, label):\n",
                "    image = tf.keras.applications.inception_v3.preprocess_input(image)\n",
                "    return image, label\n",
                "\n",
                "train_dataset_scaled = train_dataset.map(preprocess)\n",
                "validation_dataset_scaled = validation_dataset.map(preprocess)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "SHUFFLE_BUFFER_SIZE = 1000\n",
                "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
                "\n",
                "train_dataset_final = (train_dataset_scaled\n",
                "                        .cache()\n",
                "                        .shuffle(SHUFFLE_BUFFER_SIZE)\n",
                "                        .prefetch(PREFETCH_BUFFER_SIZE)\n",
                "                    )\n",
                "\n",
                "validation_dataset_final = (validation_dataset_scaled\n",
                "                            .cache()\n",
                "                            .prefetch(PREFETCH_BUFFER_SIZE))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_augmentation = tf.keras.Sequential([\n",
                "    tf.keras.layers.RandomFlip(\"Horizontal\"),\n",
                "    tf.keras.layers.RandomRotation(0.4),\n",
                "    tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
                "    tf.keras.layers.RandomContrast(0.4),\n",
                "    tf.keras.layers.RandomZoom(0.2)\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "inputs = tf.keras.Input(shape =(150,150,3))\n",
                "x = data_augmentation(inputs)\n",
                "x = model(x)\n",
                "\n",
                "model_with_aug = tf.keras.Model(inputs, x)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_with_aug.compile(\n",
                "    optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.001),\n",
                "    loss = 'binary_crossentropy',\n",
                "    metrics = ['accuracy']\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/20\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2026-01-30 10:11:38.839383: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
                    ]
                }
            ],
            "source": [
                "history = model_with_aug.fit(\n",
                "    train_dataset_final,\n",
                "    epochs=20,\n",
                "    validation_data=validation_dataset_final,\n",
                "    verbose=2\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_loss_acc(history):\n",
                "    '''Plots the training and validation loss and accuracy from a history object'''\n",
                "    acc = history.history['accuracy']\n",
                "    val_acc = history.history['val_accuracy']\n",
                "    loss = history.history['loss']\n",
                "    val_loss = history.history['val_loss']\n",
                "    \n",
                "    epochs = range(len(acc))\n",
                "    \n",
                "    fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
                "    ax[0].plot(epochs, acc, 'bo', label='Training accuracy')\n",
                "    ax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
                "    ax[0].set_title('Training and validation accuracy')\n",
                "    ax[0].set_xlabel('epochs')\n",
                "    ax[0].set_ylabel('accuracy')\n",
                "    ax[0].legend()\n",
                "    \n",
                "    ax[1].plot(epochs, loss, 'bo', label='Training Loss')\n",
                "    ax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\n",
                "    ax[1].set_title('Training and validation loss')\n",
                "    ax[1].set_xlabel('epochs')\n",
                "    ax[1].set_ylabel('loss')\n",
                "    ax[1].legend()\n",
                "    \n",
                "    plt.show()\n",
                "\n",
                "plot_loss_acc(history)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
